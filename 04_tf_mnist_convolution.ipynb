{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till now we have used single layer(accuracy ~ .92) as well as multilayer with 2 hidden layers(accuracy ~ .95) networks to classify the MNIST dataset which is not good for the real world problems.\n",
    "\n",
    "Now we are going to understand how to tie \"convolution\",\"pooling\", \"Relu\" and \"fc\" (fully-connected) layers together.\n",
    "\n",
    "Some new attributes included below are: dropout, tf.variable_scope "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST\\train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST\\train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# import \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "seed = 21\n",
    "np.random.seed = seed\n",
    "\n",
    "# import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# params\n",
    "NUM_CLASS = 10\n",
    "INPUT_SIZE = 28\n",
    "INPUT_SIZE_FLAT = INPUT_SIZE * INPUT_SIZE\n",
    "\n",
    "# network params\n",
    "LEARNING_RATE = 0.001\n",
    "DROPOUT = 0.75\n",
    "BATCH_SIZE = 128\n",
    "TRAINING_EPOCHS = 300000\n",
    "DISPLAY_STEP = 50\n",
    "\n",
    "\n",
    "# input placeholders\n",
    "images = tf.placeholder(tf.float32, [None, INPUT_SIZE_FLAT], name=\"images\")\n",
    "labels = tf.placeholder(tf.float32, [None, NUM_CLASS], name=\"labels\")\n",
    "keep_prob = tf.placeholder(tf.float32, name='dropout')\n",
    "\n",
    "# network params\n",
    "weights = {\n",
    "    # 5x5 conv filter size, 1 in_channel, 32 out_channel \n",
    "    'conv1_w': tf.Variable(tf.truncated_normal([5,5,1,32], stddev=0.1, seed=seed,name=\"conv1_w\")),\n",
    "    \n",
    "    # 5x5 conv filter size, 32 in_channel, 64 out_channel\n",
    "    'conv2_w': tf.Variable(tf.truncated_normal([5,5,32,64], stddev=0.1, seed=seed, name=\"conv2_w\")),\n",
    "    \n",
    "    # fully connected layer, 7*7*64 inputs, 1024 output\n",
    "    'fc_w': tf.Variable(tf.truncated_normal([7*7*64, 1024], stddev=0.1, seed=seed, name=\"fc_w\")),\n",
    "    \n",
    "    # output layer(softmax layer), 1024 inputs, 10 outputs [NUM_CLASS]\n",
    "    'soft_w': tf.Variable(tf.truncated_normal([1024, NUM_CLASS], stddev=0.1, seed=seed, name=\"softmax_w\"))\n",
    "}\n",
    "biases = {\n",
    "    # number of biases for conv1 layer = out_channels\n",
    "    'conv1_b': tf.Variable(tf.random_normal([32], stddev=1.0, seed=seed, name=\"conv1_b\")),\n",
    "    \n",
    "    # number of bias for conv2 layer = out_channel\n",
    "    'conv2_b': tf.Variable(tf.random_normal([64], stddev=1.0, seed=seed, name=\"conv2_b\")),\n",
    "    \n",
    "    # number of bias for fc layer = output\n",
    "    'fc_b': tf.Variable(tf.random_normal([1024], stddev=1.0, seed=seed, name=\"fc_b\")),\n",
    "    \n",
    "    # number of bias for softmax(output) layer\n",
    "    'soft_b': tf.Variable(tf.random_normal([10],stddev=1.0, seed=seed, name=\"soft_b\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model \n",
    "### `conv -> relu -> pool -> conv -> relu -> pool -> fully connected -> softmax`\n",
    "\n",
    ">tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)\n",
    "\n",
    "Computes a 2-D convolution given 4-D `input` and `filter` tensors.\n",
    "\n",
    "* input tensor of shape `[batch, in_height, in_width, in_channels]`\n",
    "* a filter / kernel tensor of shape `[filter_height, filter_width, in_channels, out_channels]`\n",
    "* Must have `strides[0] = strides[3] = 1`.  \n",
    "* For the most common case of the same horizontal and vertices strides, `strides = [1, stride, stride, 1]`.\n",
    "* Padding is `SAME` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### convolutional layer1 #######\n",
    "# reshape the input from (2d)[28x28] to (4d)[BATCH_SIZE, in_height, in_width, in_channels]\n",
    "images_reshaped = tf.reshape(images, shape=[-1, 28, 28, 1], name=\"reshape_input\")\n",
    "# conv\n",
    "conv1 = tf.nn.conv2d(input=images_reshaped, filter=weights[\"conv1_w\"], strides=[1,1,1,1], padding='SAME')\n",
    "# relu\n",
    "conv1 = tf.nn.relu(features=(conv1+biases[\"conv1_b\"]))\n",
    "# pool\n",
    "conv1 = tf.nn.max_pool(value=conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME', name=\"output_of_conv1\")\n",
    "# output dimension => BATCH_SIZE x 14 x 14 x 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### convolutional layer2 #######\n",
    "# conv\n",
    "conv2 = tf.nn.conv2d(input=conv1, filter=weights[\"conv2_w\"], strides=[1,1,1,1], padding='SAME')\n",
    "# relu\n",
    "conv2 = tf.nn.relu(features=(conv2+biases[\"conv2_b\"]))\n",
    "# pool\n",
    "conv2 = tf.nn.max_pool(value=conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME', name=\"output_of_conv2\")\n",
    "# output dimension => BATCH_SIZE x 7 x 7 x 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### fully connected layer #######\n",
    "# reshape output of conv2(4d) to (2d) to be used by fully connected layer\n",
    "fc = tf.reshape(tensor=conv2, shape=[-1, weights[\"fc_w\"].get_shape().as_list()[0]], name=\"fc_reshape\")\n",
    "\n",
    "# fc \n",
    "fc = tf.add(tf.matmul(fc,weights[\"fc_w\"]), biases[\"fc_b\"])\n",
    "# relu\n",
    "fc = tf.nn.relu(fc)\n",
    "# dropout\n",
    "fc = tf.nn.dropout(fc, keep_prob=keep_prob, seed=seed, name=\"output_of_fc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### softmax layer #######\n",
    "logits = tf.add(tf.matmul(fc, weights[\"soft_w\"]), biases[\"soft_b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "# loss\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "# optimizer \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE,name='Adam').minimize(loss)\n",
    "# accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 6400, batch_loss 1.5000, acc 0.625\n",
      "iter 12800, batch_loss 0.3078, acc 0.875\n",
      "iter 19200, batch_loss 0.2291, acc 0.9297\n",
      "iter 25600, batch_loss 0.1396, acc 0.9609\n",
      "iter 32000, batch_loss 0.0941, acc 0.9766\n",
      "iter 38400, batch_loss 0.0823, acc 0.9766\n",
      "iter 44800, batch_loss 0.0873, acc 0.9688\n",
      "iter 51200, batch_loss 0.1185, acc 0.9688\n",
      "iter 57600, batch_loss 0.0461, acc 0.9844\n",
      "iter 64000, batch_loss 0.1045, acc 0.9844\n",
      "iter 70400, batch_loss 0.0346, acc 0.9844\n",
      "iter 76800, batch_loss 0.0962, acc 0.9531\n",
      "iter 83200, batch_loss 0.0429, acc 0.9922\n",
      "iter 89600, batch_loss 0.0246, acc 0.9922\n",
      "iter 96000, batch_loss 0.0390, acc 0.9844\n",
      "iter 102400, batch_loss 0.0139, acc 1.0\n",
      "iter 108800, batch_loss 0.0211, acc 0.9844\n",
      "iter 115200, batch_loss 0.0340, acc 0.9844\n",
      "iter 121600, batch_loss 0.0517, acc 0.9609\n",
      "iter 128000, batch_loss 0.0616, acc 0.9766\n",
      "iter 134400, batch_loss 0.0330, acc 0.9844\n",
      "iter 140800, batch_loss 0.0215, acc 0.9844\n",
      "iter 147200, batch_loss 0.0067, acc 1.0\n",
      "iter 153600, batch_loss 0.0446, acc 0.9844\n",
      "iter 160000, batch_loss 0.0604, acc 0.9766\n",
      "iter 166400, batch_loss 0.0302, acc 0.9844\n",
      "iter 172800, batch_loss 0.0158, acc 0.9922\n",
      "iter 179200, batch_loss 0.0094, acc 1.0\n",
      "iter 185600, batch_loss 0.0509, acc 0.9844\n",
      "iter 192000, batch_loss 0.0254, acc 0.9844\n",
      "iter 198400, batch_loss 0.0247, acc 0.9922\n",
      "iter 204800, batch_loss 0.0427, acc 0.9844\n",
      "iter 211200, batch_loss 0.0097, acc 1.0\n",
      "iter 217600, batch_loss 0.0164, acc 1.0\n",
      "iter 224000, batch_loss 0.0194, acc 0.9922\n",
      "iter 230400, batch_loss 0.0062, acc 1.0\n",
      "iter 236800, batch_loss 0.0468, acc 0.9766\n",
      "iter 243200, batch_loss 0.0056, acc 1.0\n",
      "iter 249600, batch_loss 0.0251, acc 0.9844\n",
      "iter 256000, batch_loss 0.0165, acc 0.9922\n",
      "iter 262400, batch_loss 0.0283, acc 0.9922\n",
      "iter 268800, batch_loss 0.0028, acc 1.0\n",
      "iter 275200, batch_loss 0.0185, acc 0.9922\n",
      "iter 281600, batch_loss 0.0120, acc 0.9922\n",
      "iter 288000, batch_loss 0.0069, acc 1.0\n",
      "iter 294400, batch_loss 0.0066, acc 1.0\n",
      "optimization finished\n",
      "Testing accuracy  0.984375\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    while step * BATCH_SIZE < TRAINING_EPOCHS:\n",
    "        batch_images, batch_labels = mnist.train.next_batch(BATCH_SIZE)\n",
    "        \n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(fetches=optimizer, feed_dict={images:batch_images, labels:batch_labels, keep_prob:DROPOUT})\n",
    "        \n",
    "        if step % DISPLAY_STEP == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            los, acc = sess.run([loss, accuracy], feed_dict={images:batch_images, labels:batch_labels, keep_prob:1.0})\n",
    "            \n",
    "            print(\"iter \" + str(step*BATCH_SIZE) + \", batch_loss \" + \"{:.4f}\".format(los) + \", acc \"+ \"{:.4}\".format(acc))\n",
    "        \n",
    "        step += 1\n",
    "    \n",
    "    print(\"optimization finished\")\n",
    "    \n",
    "    # time to calculate test accuracy\n",
    "    print(\"Testing accuracy \", sess.run(fetches=accuracy,feed_dict={images:mnist.test.images[:128], \n",
    "                                                                    labels:mnist.test.labels[:128],\n",
    "                                                                    keep_prob:1.0}))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
